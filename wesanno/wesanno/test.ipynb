{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 4 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "# Standard modules\n",
    "from dataclasses import dataclass\n",
    "from logging import getLogger, StreamHandler, DEBUG, config\n",
    "import os\n",
    "\n",
    "# Third party modules\n",
    "import gffutils\n",
    "import pybedtools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib2 import Path\n",
    "import pysam\n",
    "from tqdm import tqdm\n",
    "import yaml\n",
    "\n",
    "# Local modules\n",
    "from libs.args import parser_setting\n",
    "from libs.utils import load_config, OutputSettings\n",
    "from libs.preprocess import PreProcessExomeSummary\n",
    "from libs.modesamples import ModeSamples\n",
    "from libs.annolibs.anno import Anno\n",
    "from libs.annolibs.genebased import GeneBasedAnno\n",
    "from libs.filter.maffilter import MafFilter\n",
    "from libs.filter.typefilter import TypeFilter\n",
    "from libs.filter.gtfilter import GtFilter\n",
    "from libs.filter.counter import counter\n",
    "\n",
    "# Settings\n",
    "tqdm.pandas()\n",
    "\n",
    "#----- STEP 0. Logging settings\n",
    "# parent_directory = os.path.dirname(os.path.dirname(__file__))\n",
    "parent_directory = os.path.dirname(os.path.abspath('../__file__'))\n",
    "config_path: str = os.path.join(parent_directory, 'config/logging.yaml')\n",
    "with open(config_path, 'r') as f:\n",
    "    config.dictConfig(yaml.safe_load(f))\n",
    "logger = getLogger(__name__)\n",
    "\n",
    "# http://www.openbioinformatics.org/annovar/download/0wgxR2rIVP/annovar.latest.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024/01/16 02:39:45 [INFO   ] (libs.args) - Arguments are as follows:\n",
      "\n",
      "     input: /Volumes/vol/work/Github/TestData/proband/IRUD_HRS/annovar/exome_summary.20230413_190252.txt\n",
      "     output: None\n",
      "     xhmm: /work/Github/TestData/proband/xhmm/data.segdup.strvar.haplo.deciph.omim.xcnv.gene.uniq\n",
      "     phenotype: None\n",
      "     mode: quad_unaffected\n",
      "     samples: auto\n",
      "     assembly: hg19\n",
      "     config: /Volumes/vol/work/Github/playground/wesanno/config/config.toml\n",
      "     resources: /Volumes/vol/work/Github/playground/wesanno/resources\n",
      "     no_gnomad: False\n",
      "     no_hgmd: False\n",
      "     no_decipher: False\n",
      "     no_ddg2p: False\n",
      "     no_jarvis: False\n",
      "     no_spliceai: False\n",
      "     no_syno: None\n",
      "     no_alphamissense: False\n",
      "     no_revel: False\n",
      "     no_trap: False\n",
      "     excel_formating: True\n",
      "\n",
      "\n",
      "2024/01/16 02:39:45 [INFO   ] (libs.preprocess) - Liftover to hg38 is started\n",
      "2024/01/16 02:39:45 [INFO   ] (libs.preprocess) - It takes about 5 minutes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e4b1c968fce4ebca3728811eb7a3a74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=2910), Label(value='0 / 2910'))), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024/01/16 02:43:50 [INFO   ] (libs.preprocess) - Extract InHouse MAF\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab5855a575954f0cb47427990b8f6fc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=2910), Label(value='0 / 2910'))), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcd02b37cc4742edb8984535e2ed536c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=2910), Label(value='0 / 2910'))), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "859359ee7b3e490fa9c297b9dafb1751",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=2910), Label(value='0 / 2910'))), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024/01/16 02:43:58 [INFO   ] (libs.preprocess) - Extract MAF from each database cols\n",
      "2024/01/16 02:43:58 [INFO   ] (libs.preprocess) - Extract genotypeing info\n",
      "2024/01/16 02:43:58 [INFO   ] (libs.preprocess) - Split QC info\n",
      "2024/01/16 02:43:58 [INFO   ] (libs.preprocess) - Replace \".\" to np.nan\n",
      "2024/01/16 02:43:58 [INFO   ] (libs.preprocess) - Split ALT column\n",
      "2024/01/16 02:44:00 [INFO   ] (libs.preprocess) - Drop unused columns\n"
     ]
    }
   ],
   "source": [
    "#-----   STEP 1. Argument settings\n",
    "args = parser_setting()\n",
    "\n",
    "#-----   STEP 2. Input file and Output settings\n",
    "df = pd.read_table(args['input'], header=0, dtype=str)\n",
    "configs: dict = load_config(args['config'])\n",
    "\n",
    "#-----   STEP 3. Get Mode and Samples information\n",
    "modesamples = ModeSamples(df=df, args=args)\n",
    "mode_samples_info = modesamples.get_mode_samples_info()\n",
    "logger.info(f\"mode_samples_info: {mode_samples_info.mode}\")\n",
    "\n",
    "#-----   STEP 4. Output settings\n",
    "output_settings = OutputSettings(\n",
    "    args=args, mode_samples_info=mode_samples_info)\n",
    "output_file_path = output_settings.get_saving_file_path()\n",
    "\n",
    "#-----   STEP 5. Pre-processing\n",
    "preprocessing = PreProcessExomeSummary(\n",
    "    df=df, args=args, mode_samples_info=mode_samples_info)\n",
    "df = preprocessing.all_pre_processing()\n",
    "\n",
    "#-----   STEP 6. Annotation\n",
    "genebasedanno = GeneBasedAnno(args['resources'])\n",
    "df = genebasedanno.anno_hgmd(df=df)\n",
    "\n",
    "#-----   STEP 7. Filtering\n",
    "maffilter = MafFilter(\n",
    "    df=df, mode_samples_info=mode_samples_info, config=configs)\n",
    "df = maffilter.all_filtering()\n",
    "\n",
    "typefilter = TypeFilter(df=df)\n",
    "df = typefilter.exclude_hlamuc_and_exonicsyno()\n",
    "\n",
    "gtfilter = GtFilter(\n",
    "    df=df, mode_samples_info=mode_samples_info)\n",
    "dfs = gtfilter.genotypeing_filter()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#-----   STEP 8. Output as an Excel \n",
    "def df_to_excel(dfs: dataclass, output_xlsx) -> None:\n",
    "    sheet_names = ['AD', 'Homo', 'CH', 'XL']\n",
    "    with pd.ExcelWriter(output_xlsx) as writer:\n",
    "        for df, sheet_name in zip([dfs.AD, dfs.Hm, dfs.CH, dfs.XL], sheet_names):\n",
    "            df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "df_to_excel(dfs, f\"{output_file_path}.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     AD   Homo     CH     XL\n",
      "All variants      11649  11649  11649  11649\n",
      "Chrom. Filter     11318  11318  11318    331\n",
      "GT Fitler           156    156   4194    254\n",
      "MAF Filter           11     13    731     51\n",
      "In-House Filter       9     12    460     26\n",
      "Exclude HLA/MUC       9     12    368     26\n",
      "Exclude Ex.Syno.      9     12    305     19\n"
     ]
    }
   ],
   "source": [
    "#-----   STEP (Final Step). Count variants of filtering process\n",
    "countsummery_file = str(Path(output_file_path).parent) + '/CountSummary.xlsx'\n",
    "counter_result = counter(dfs=dfs, output_excel=countsummery_file)\n",
    "print(counter_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----   STEP 6. Additional annotations\n",
    "anno = Anno(df=df, args=args)\n",
    "df = anno.anno_scores()\n",
    "\n",
    "#-----   STEP 7. Filtering\n",
    "maffilter = MafFilter(\n",
    "    df=df, mode_samples_info=mode_samples_info, config=configs)\n",
    "df = maffilter.all_filtering()\n",
    "\n",
    "typefilter = TypeFilter(df=df)\n",
    "df = typefilter.exclude_hlamuc_and_exonicsyno()\n",
    "\n",
    "gtfilter = GtFilter(\n",
    "    df=df, mode_samples_info=mode_samples_info)\n",
    "dfs = gtfilter.genotypeing_filter()\n",
    "\n",
    "#-----   STEP 8. Output as an Excel \n",
    "def df_to_excel(dfs: dataclass, output_xlsx) -> None:\n",
    "    sheet_names = ['AD', 'Homo', 'CH', 'XL']\n",
    "    with pd.ExcelWriter(output_xlsx) as writer:\n",
    "        for df, sheet_name in zip([dfs.AD, dfs.Hm, dfs.CH, dfs.XL], sheet_names):\n",
    "            df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "df_to_excel(dfs, f\"{output_file_path}.xlsx\")\n",
    "\n",
    "############################################\n",
    "import pickle\n",
    "with open(f\"{output_file_path}.pkl\", mode=\"wb\") as f:\n",
    "    pickle.dump(dfs, f)\n",
    "############################################\n",
    "\n",
    "#-----   STEP (Final Step). Count variants of filtering process\n",
    "countsummery_file = str(Path(output_file_path).parent) + '/CountSummary.xlsx'\n",
    "counter_result = counter(dfs=dfs, output_excel=countsummery_file)\n",
    "print(counter_result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'libs.filter.gtfilter.ModelDataFrame'>\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "pkl = '/work/Github/TestData/trio/29881/Sample_29881-trio_results/Sample_29881-trio.tsv.pkl'\n",
    "with open(pkl, mode='rb') as f:\n",
    "    dfs = pickle.load(f)\n",
    "\n",
    "print(type(dfs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "hgmd_pkl = '/work/resources/HGMD/hgmd_info_2023.3'\n",
    "hgmd = pd.read_pickle(hgmd_pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene</th>\n",
       "      <th>altsymbol</th>\n",
       "      <th>refseq</th>\n",
       "      <th>expected_inheritance</th>\n",
       "      <th>hgncID</th>\n",
       "      <th>omimid</th>\n",
       "      <th>DFP</th>\n",
       "      <th>DM</th>\n",
       "      <th>DM?</th>\n",
       "      <th>DP</th>\n",
       "      <th>FP</th>\n",
       "      <th>R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RBFOX1</td>\n",
       "      <td>2BP1|A2BP1|FOX-1|FOX1|HRNBP1</td>\n",
       "      <td>NM_145891.3</td>\n",
       "      <td>AD</td>\n",
       "      <td>18222</td>\n",
       "      <td>605104</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABCA3</td>\n",
       "      <td>ABC-C|ABC3|EST111653|LBM180|SMDP3</td>\n",
       "      <td>NM_001089.3</td>\n",
       "      <td>AR</td>\n",
       "      <td>33</td>\n",
       "      <td>601615</td>\n",
       "      <td>0.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AKAP13</td>\n",
       "      <td>AKAP-13|AKAP-Lbc|ARHGEF13|BRX|c-lbc|HA-3|Ht31|...</td>\n",
       "      <td>NM_007200.5</td>\n",
       "      <td>UNK</td>\n",
       "      <td>371</td>\n",
       "      <td>604686</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GSS</td>\n",
       "      <td>GSHS|HEL-S-64p|HEL-S-88n</td>\n",
       "      <td>NM_000178.4</td>\n",
       "      <td>AR</td>\n",
       "      <td>4624</td>\n",
       "      <td>601002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BRF1</td>\n",
       "      <td>BRF|BRF-1|CFDS|GTF3B|hBRF|HEL-S-76p|TAF3B2|TAF...</td>\n",
       "      <td>NM_001519.4</td>\n",
       "      <td>ADAR</td>\n",
       "      <td>11551</td>\n",
       "      <td>604902</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17668</th>\n",
       "      <td>TNFRSF21</td>\n",
       "      <td>BM-018|CD358|DR6</td>\n",
       "      <td>NM_014452.5</td>\n",
       "      <td>UNK</td>\n",
       "      <td>13469</td>\n",
       "      <td>605732</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17669</th>\n",
       "      <td>C12orf4</td>\n",
       "      <td>MRT66</td>\n",
       "      <td>NM_020374.4</td>\n",
       "      <td>AR</td>\n",
       "      <td>1184</td>\n",
       "      <td>616082</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17670</th>\n",
       "      <td>DMBX1</td>\n",
       "      <td>Atx|MBX|OTX3|PAXB</td>\n",
       "      <td>NM_147192.3</td>\n",
       "      <td>UNK</td>\n",
       "      <td>19026</td>\n",
       "      <td>607410</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17671</th>\n",
       "      <td>WDR93</td>\n",
       "      <td>C1d-87|CFAP297|FAP297</td>\n",
       "      <td>NM_020212.2</td>\n",
       "      <td>UNK</td>\n",
       "      <td>26924</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17672</th>\n",
       "      <td>ETV6</td>\n",
       "      <td>TEL|TEL/ABL|THC5</td>\n",
       "      <td>NM_001987.5</td>\n",
       "      <td>AD</td>\n",
       "      <td>3495</td>\n",
       "      <td>600618</td>\n",
       "      <td>2.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17673 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           gene                                          altsymbol  \\\n",
       "0        RBFOX1                       2BP1|A2BP1|FOX-1|FOX1|HRNBP1   \n",
       "1         ABCA3                  ABC-C|ABC3|EST111653|LBM180|SMDP3   \n",
       "2        AKAP13  AKAP-13|AKAP-Lbc|ARHGEF13|BRX|c-lbc|HA-3|Ht31|...   \n",
       "3           GSS                           GSHS|HEL-S-64p|HEL-S-88n   \n",
       "4          BRF1  BRF|BRF-1|CFDS|GTF3B|hBRF|HEL-S-76p|TAF3B2|TAF...   \n",
       "...         ...                                                ...   \n",
       "17668  TNFRSF21                                   BM-018|CD358|DR6   \n",
       "17669   C12orf4                                              MRT66   \n",
       "17670     DMBX1                                  Atx|MBX|OTX3|PAXB   \n",
       "17671     WDR93                              C1d-87|CFAP297|FAP297   \n",
       "17672      ETV6                                   TEL|TEL/ABL|THC5   \n",
       "\n",
       "            refseq expected_inheritance hgncID  omimid  DFP     DM    DM?  \\\n",
       "0      NM_145891.3                   AD  18222  605104  0.0   15.0   47.0   \n",
       "1      NM_001089.3                   AR     33  601615  0.0  230.0  152.0   \n",
       "2      NM_007200.5                  UNK    371  604686  0.0    0.0   11.0   \n",
       "3      NM_000178.4                   AR   4624  601002  0.0   40.0    5.0   \n",
       "4      NM_001519.4                 ADAR  11551  604902  0.0   19.0   15.0   \n",
       "...            ...                  ...    ...     ...  ...    ...    ...   \n",
       "17668  NM_014452.5                  UNK  13469  605732  0.0    4.0    7.0   \n",
       "17669  NM_020374.4                   AR   1184  616082  0.0    7.0    4.0   \n",
       "17670  NM_147192.3                  UNK  19026  607410  0.0    1.0    5.0   \n",
       "17671  NM_020212.2                  UNK  26924    None  0.0    1.0    1.0   \n",
       "17672  NM_001987.5                   AD   3495  600618  2.0   39.0   38.0   \n",
       "\n",
       "        DP   FP    R  \n",
       "0      4.0  0.0  0.0  \n",
       "1      1.0  2.0  0.0  \n",
       "2      1.0  5.0  0.0  \n",
       "3      0.0  0.0  0.0  \n",
       "4      0.0  0.0  0.0  \n",
       "...    ...  ...  ...  \n",
       "17668  0.0  0.0  0.0  \n",
       "17669  0.0  0.0  0.0  \n",
       "17670  0.0  0.0  0.0  \n",
       "17671  0.0  0.0  0.0  \n",
       "17672  1.0  0.0  0.0  \n",
       "\n",
       "[17673 rows x 12 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genocode_file_hg19 = '/resources/GENCODE_Basic_Annotations/gencode.v44lift37.basic.annotation.gtf.gz'\n",
    "genocode_db_hg19 = '/resources/GENCODE_Basic_Annotations/gencode.v44lift37.basic.annotation.db.bak'\n",
    "\n",
    "db = gffutils.FeatureDB(genocode_db_hg19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "@dataclass\n",
    "class GencodeInfo:\n",
    "    gene_name: str\n",
    "    hgnc: str\n",
    "    ensg: str\n",
    "    enst: str\n",
    "    ensg_full: str\n",
    "    enst_full: str\n",
    "    strand: str\n",
    "\n",
    "def __anno_gencode_info(row) -> str:\n",
    "    query_region: str = f\"chr{row['CHROM']}:{row['POS']}-{row['POS']}\"\n",
    "    # query_region: str = f\"chr17:1132706-1132706\"\n",
    "    fetched_data = db.region(region=query_region, \n",
    "                            featuretype='gene',\n",
    "                            completely_within=False)\n",
    "    \n",
    "    result = []\n",
    "    while 1:\n",
    "        try:\n",
    "            data = next(fetched_data)\n",
    "        except StopIteration:\n",
    "            break\n",
    "        else:\n",
    "            strand = data.strand\n",
    "            gene_name = data.attributes['gene_name'][0]\n",
    "            \n",
    "            try:\n",
    "                ensg_full = data.attributes['gene_id'][0]\n",
    "            except KeyError:\n",
    "                ensg = '.'\n",
    "            else:\n",
    "                ensg = re.match(r'ENSG\\d+', ensg_full).group()\n",
    "    \n",
    "    # print(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "@dataclass\n",
    "class GencodeInfo:\n",
    "    gene_name: str\n",
    "    hgnc: str\n",
    "    ensg: str\n",
    "    enst: str\n",
    "    ensg_full: str\n",
    "    enst_full: str\n",
    "    strand: str\n",
    "\n",
    "def __anno_gencode_info(row) -> str:\n",
    "    query_region: str = f\"chr{row['CHROM']}:{row['POS']}-{row['POS']}\"\n",
    "    # query_region: str = f\"chr17:1132706-1132706\"\n",
    "    fetched_data = db.region(region=query_region, \n",
    "                            featuretype='gene',\n",
    "                            completely_within=False)\n",
    "    \n",
    "    result = []\n",
    "    while 1:\n",
    "        try:\n",
    "            data = next(fetched_data)\n",
    "        except StopIteration:\n",
    "            break\n",
    "        else:\n",
    "            strand = data.strand\n",
    "            gene_name = data.attributes['gene_name'][0]\n",
    "\n",
    "            try:\n",
    "                hgnc_info = data.attributes['hgnc_id'][0]\n",
    "            except KeyError:\n",
    "                hgnc = '.'\n",
    "            else:\n",
    "                hgnc = re.search(r'\\d+', hgnc_info).group()\n",
    "            \n",
    "            try:\n",
    "                ensg_full = data.attributes['gene_id'][0]\n",
    "            except KeyError:\n",
    "                ensg = '.'\n",
    "            else:\n",
    "                ensg = re.match(r'ENSG\\d+', ensg_full).group()\n",
    "            \n",
    "            try:\n",
    "                enst_full = data.attributes['transcript_id'][0]\n",
    "            except KeyError:\n",
    "                enst = '.'\n",
    "            else:\n",
    "                enst = re.match(r'ENST\\d+', enst_full).group()\n",
    "\n",
    "            genecode_info = GencodeInfo(\n",
    "                gene_name, hgnc, ensg, enst, ensg_full, enst_full, strand)\n",
    "            result.append(genecode_info)\n",
    "    \n",
    "    # print(result)\n",
    "    return result\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_region: str = f\"chr17:1132706-1132706\"\n",
    "fetched_data = db.region(region=query_region, \n",
    "                            featuretype='transcript',\n",
    "                            completely_within=False)\n",
    "    \n",
    "result = []\n",
    "while 1:\n",
    "    try:\n",
    "        data = next(fetched_data)\n",
    "    except StopIteration:\n",
    "        break\n",
    "    else:\n",
    "        strand = data.strand\n",
    "        gene_name = data.attributes['gene_name'][0]\n",
    "\n",
    "        try:\n",
    "            hgnc_info = data.attributes['hgnc_id'][0]\n",
    "        except KeyError:\n",
    "            hgnc = '.'\n",
    "        else:\n",
    "            hgnc = re.search(r'\\d+', hgnc_info).group()\n",
    "        \n",
    "        try:\n",
    "            ensg_full = data.attributes['gene_id'][0]\n",
    "        except KeyError:\n",
    "            ensg = '.'\n",
    "        else:\n",
    "            ensg = re.match(r'ENSG\\d+', ensg_full).group()\n",
    "        \n",
    "        try:\n",
    "            enst_full = data.attributes['transcript_id'][0]\n",
    "        except KeyError:\n",
    "            enst = '.'\n",
    "        else:\n",
    "            enst = re.match(r'ENST\\d+', enst_full).group()\n",
    "\n",
    "        genecode_info = GencodeInfo(\n",
    "            gene_name, hgnc, ensg, enst, ensg_full, enst_fuœll, strand)\n",
    "        result.append(genecode_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_region: str = f\"chr17:1132706-1132706\"\n",
    "fetched_gene = db.region(region=query_region, \n",
    "                         featuretype=['gene', 'transcript'],\n",
    "                         completely_within=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chr17\tHAVANA\tgene\t906759\t1133032\t.\t-\t.\tgene_id \"ENSG00000159842.16_14\"; gene_type \"protein_coding\"; gene_name \"ABR\"; level \"1\"; hgnc_id \"HGNC:81\"; tag \"ncRNA_host\"; havana_gene \"OTTHUMG00000090313.18_14\"; remap_status \"full_contig\"; remap_num_mappings \"1\"; remap_target_status \"overlap\";\n"
     ]
    }
   ],
   "source": [
    "for data in fetched_gene:\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtf = db.children('', featuretype='transcript', order_by='start')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for g in gtf:\n",
    "    print(g)\n",
    "    print(g.attributes['tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6443/6443 [01:25<00:00, 75.63it/s] \n"
     ]
    }
   ],
   "source": [
    "\n",
    "df['gencode'] = df.progress_apply(__anno_gencode_info, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in df.iterrows():\n",
    "    print(row[0], row[1]['Gene.refGene'], row[1]['gencode'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chr1\tHAVANA\ttranscript\t65419\t71585\t.\t+\t.\tgene_id \"ENSG00000186092.7_9\"; transcript_id \"ENST00000641515.2_5\"; gene_type \"protein_coding\"; gene_name \"OR4F5\"; transcript_type \"protein_coding\"; transcript_name \"OR4F5-201\"; level \"2\"; protein_id \"ENSP00000493376.2\"; hgnc_id \"HGNC:14825\"; tag \"RNA_Seq_supported_partial\"; tag \"basic\"; tag \"Ensembl_canonical\"; tag \"MANE_Select\"; tag \"appris_principal_1\"; tag \"CCDS\"; ccdsid \"CCDS30547.2\"; havana_gene \"OTTHUMG00000001094.4_9\"; havana_transcript \"OTTHUMT00000003223.4_5\"; remap_num_mappings \"1\"; remap_status \"full_contig\"; remap_target_status \"new\";\n",
      "Strand: +\n",
      "ENSG_Full: ENSG00000186092.7_9\n",
      "ENSG     : ENSG00000186092\n",
      "ENST_Full: ENST00000641515.2_5\n",
      "ENST     : ENST00000641515\n",
      "GeneName : OR4F5\n",
      "HGNC_ID  : 14825\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "query_region: str = f'chr1: 69610-69610'\n",
    "rows = db.region(region=query_region, featuretype='transcript')\n",
    "\n",
    "for row in rows:\n",
    "    print(row)\n",
    "\n",
    "    enst_full = row.attributes['transcript_id'][0]\n",
    "    ensg_full = row.attributes['gene_id'][0]\n",
    "    hgnc_info = row.attributes['hgnc_id'][0]\n",
    "\n",
    "    try:\n",
    "        enst = re.match(r'ENST\\d+', enst_full).group()\n",
    "    except AttributeError:\n",
    "        enst = '.'\n",
    "    try:\n",
    "        ensg = re.match(r'ENSG\\d+', ensg_full).group()\n",
    "    except AttributeError:\n",
    "        ensg = '.'\n",
    "    try:\n",
    "        hgnc = re.search(r'\\d+', hgnc_info).group()\n",
    "    except AttributeError:\n",
    "        hgnc = '.'\n",
    "\n",
    "    print(f\"Strand: {row.strand}\")\n",
    "    print(f\"GeneName : {row.attributes['gene_name'][0]}\")\n",
    "    print(f\"HGNC_ID  : {hgnc}\")\n",
    "    print(f\"ENSG_Full: {ensg_full}\")\n",
    "    print(f\"ENSG     : {ensg}\")\n",
    "    print(f\"ENST_Full: {enst_full}\")\n",
    "    print(f\"ENST     : {enst}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----   STEP 5. Pre-processing\n",
    "preprocessing = PreProcessExomeSummary(\n",
    "    df=df, mode_samples_info=mode_samples_info)\n",
    "df = preprocessing.all_pre_processing()\n",
    "\n",
    "#-----   STEP 6. Additional annotations\n",
    "anno = Anno(df=df, args=args)\n",
    "df = anno.anno_scores()\n",
    "\n",
    "#-----   STEP 7. Filtering\n",
    "maffilter = MafFilter(\n",
    "    df=df, mode_samples_info=mode_samples_info, config=config)\n",
    "df = maffilter.all_filtering()\n",
    "\n",
    "typefilter = TypeFilter(df=df)\n",
    "df = typefilter.exclude_hlamuc_and_exonicsyno()\n",
    "\n",
    "gtfilter = GtFilter(\n",
    "    df=df, mode_samples_info=mode_samples_info)\n",
    "dfs = gtfilter.genotypeing_filter()\n",
    "\n",
    "#-----   STEP 9. Output as an Excel \n",
    "def df_to_excel(dfs: dataclass, output_xlsx) -> None:\n",
    "    sheet_names = ['AD', 'Homo', 'CH', 'XL']\n",
    "    with pd.ExcelWriter(output_xlsx) as writer:\n",
    "        for df, sheet_name in zip([dfs.AD, dfs.Hm, dfs.CH, dfs.XL], sheet_names):\n",
    "            df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "output_xlsx = f\"{output_file_path}.xlsx\"\n",
    "output_pickle = f\"{output_file_path}.pkl\"\n",
    "df_to_excel(dfs, output_xlsx)\n",
    "dfs.to_pickle(output_pickle)\n",
    "\n",
    "#-----   STEP 8. Count variants of filtering process\n",
    "countsummery_file = str(Path(output_file_path).parent) + '/CountSummary.xlsx'\n",
    "counter_result = counter(dfs=dfs, output_excel=countsummery_file)\n",
    "print(counter_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['InHouse_absent_FILTER', 'InHouse_1%_FILTER', 'MAF_0.1%_FILTER',\n",
       "       'MAF_1%_FILTER', 'HLAMUC_FILTER', 'ExonicSyno_FILTER', 'GT_FILTER'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs.AD.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/work/Github/TestData/trio/29881/Sample_29881-trio_results/Sample_29881-trio.tsv\n"
     ]
    }
   ],
   "source": [
    "print(output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----   STEP 9. Output as an Excel \n",
    "def df_to_excel(dfs: dataclass, output_xlsx) -> None:\n",
    "    sheet_names = ['AD', 'Homo', 'CH', 'XL']\n",
    "    with pd.ExcelWriter(output_xlsx) as writer:\n",
    "        for df, sheet_name in zip([dfs.AD, dfs.Hm, dfs.CH, dfs.XL], sheet_names):\n",
    "            df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "output_xlsx = f\"{output_file_path}.xlsx\"\n",
    "df_to_excel(dfs, output_xlsx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sample_32741-proband_countsummary.txt'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hgmd_resource: str = [\n",
    "    str(x) for x in self.resources_dir.glob('HGMD/HGMD_gene_based.tsv.gz')][0]\n",
    "        return pd.read_csv(hgmd_resource, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "couter_result = counter(dfs=dfs, output_excel=output_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = counter(dfs=dfs, output_excel='./test.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('./post7.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('./post7.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----   STEP 8. Output as an Excel \n",
    "output_xlsx = './head100.xlsx'\n",
    "def df_to_excel(dfs: dataclass, output_xlsx) -> None:\n",
    "    sheet_names = ['AD', 'Homo', 'CH', 'XL']\n",
    "    with pd.ExcelWriter(output_xlsx) as writer:\n",
    "        for df, sheet_name in zip([dfs.AD, dfs.Hm, dfs.CH, dfs.XL], sheet_names):\n",
    "            df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "df_to_excel(dfs, 'output_xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----   STEP 9. Insert hyperlinks\n",
    "# 0. 最初にエクセルを読み込む\n",
    "# 1. メモ用の列を作る (1-2列目)\n",
    "# 2. リンク挿入用の列を作る (3-7列目)\n",
    "# 3. リンクの挿入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formatng ......\n"
     ]
    }
   ],
   "source": [
    "from libs.excelibs.excel_format import ExcelFormat\n",
    "from libs.excelibs.hyperlinks import HyperLinks\n",
    "\n",
    "excelformat = ExcelFormat('./test1.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excelformat.insert_comment_cols()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excelformat.insert_hyperlink_cols()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excelformat.workbook.save('./test2.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CREATE dbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create db for gffutils\n",
    "import gffutils\n",
    "import gffutils.pybedtools_integration\n",
    "\n",
    "\n",
    "genocode_file_hg19 = '/resources/GENCODE_Basic_Annotations/gencode.v44lift37.basic.annotation.gtf.gz'\n",
    "genocode_db_hg19 = '/resources/GENCODE_Basic_Annotations/gencode.v44lift37.basic.annotation.db'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = gffutils.create_db(data=genocode_file_hg19, dbfn=genocode_db_hg19, \n",
    "                        disable_infer_genes=True,\n",
    "                        disable_infer_transcripts=True,\n",
    "                        keep_order=True, \n",
    "                        force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BedTool(/resources/GENCODE_Basic_Annotations/gencode.v44lift37.basic.annotation.intron.db)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genocode_db_intron_hg19 = '/resources/GENCODE_Basic_Annotations/gencode.v44lift37.basic.annotation.intron.db'\n",
    "\n",
    "db = gffutils.FeatureDB(genocode_db_hg19)\n",
    "introns = db.create_introns(exon_featuretype='exon', \n",
    "                            new_featuretype='intron', \n",
    "                            merge_attributes=True, \n",
    "                            numeric_sort=True)\n",
    "pybed = gffutils.pybedtools_integration.to_bedtool(introns)\n",
    "pybed.saveas(genocode_db_intron_hg19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_intoron_gtf(db: gffutils.FeatureDB, output: str) -> None:\n",
    "    introns = db.create_introns(exon_featuretype='exon', \n",
    "                                new_featuretype='intron', \n",
    "                                merge_attributes=True, \n",
    "                                numeric_sort=True)\n",
    "    pybed = gffutils.pybedtools_integration.to_bedtool(introns)\n",
    "    pybed.saveas(output)\n",
    "    \n",
    "    return"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wesanno",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
