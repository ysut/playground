{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import glob\n",
    "\n",
    "\n",
    "# Set up logger\n",
    "from logging import getLogger, StreamHandler, Formatter, INFO\n",
    "\n",
    "logger = getLogger(__name__)\n",
    "format = Formatter(fmt='%(asctime)s [%(levelname)s] - %(message)s',\n",
    "                   datefmt='%Y-%m-%d %H:%M:%S')\n",
    "handler = StreamHandler()\n",
    "handler.setLevel(INFO)\n",
    "handler.setFormatter(format)\n",
    "logger.addHandler(handler)\n",
    "logger.setLevel(INFO)\n",
    "logger.propagate = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns to use\n",
    "usecols_new = ['Date', 'YCU ID', 'DNA ID', '病名', 'State', 'Gene', 'WES batch', \n",
    "               '家族関係', 'father DNA ID', 'mother DNA ID', 'Proband_DNA_ID']\n",
    "\n",
    "usecols_old = ['Date', 'YCU ID', 'DNA ID', '病名', 'WES batch', \n",
    "               '家族関係', 'father DNA ID', 'mother DNA ID', 'Proband_DNA_ID']\n",
    "\n",
    "usecols_post = ['検体拝受日', 'YCUID', 'DNAID', '診断名', 'State', \n",
    "                '解析結果(遺伝子名)', 'ProbandID']\n",
    "\n",
    "## Find the old excel file and the latest excel file\n",
    "logger.info(\"Find the excel filed\")\n",
    "old_excel = glob.glob('rawdata/2004*.xlsx')[0]\n",
    "new_excel = glob.glob('rawdata/自動報告書*')[0]\n",
    "post_excel = glob.glob('rawdata/郵送*')[0]\n",
    "\n",
    "# Load excel files as pd.DataFrame\n",
    "logger.info(f\"Load {new_excel} file\")\n",
    "df = pd.read_excel(new_excel, dtype=str, sheet_name='database', \n",
    "                   index_col=None, skiprows=3, usecols=usecols_new)\n",
    "df.dropna(how='all')\n",
    "df = df[usecols_new]\n",
    "\n",
    "logger.info(f\"Load {old_excel} file\")\n",
    "df_old = pd.read_excel(old_excel, index_col=None, usecols=usecols_old)\n",
    "df_old.dropna(how='all')\n",
    "df_old = df_old[usecols_old]\n",
    "\n",
    "logger.info(f\"Load {post_excel} file\")\n",
    "df_post = pd.read_excel(post_excel, index_col=None, usecols=usecols_post)\n",
    "df_post.dropna(how='all')\n",
    "df_post = df_post[usecols_post]\n",
    "\n",
    "# Pre-porcessing for State information\n",
    "replace_to_identified = [\n",
    "    '89717692', '22006383', '166210771', '18602433', '18598085', '53279465', \n",
    "    '6495539', '89653823', '89712015', '37840968', '47990943', '24024725', \n",
    "    '39929311', '29,610,505', '50607726', '50607674', '75959244', '220154743', \n",
    "    '220156581', '56385389', '8242896', '166909430', '153363092', '166237229',\n",
    "    '62070967', '105834449', '130422388', '1736004', '52082841', '101953473',\n",
    "    '101953473', 'Confirm', 'SNV_identified', 'CNV_identified', 'SV_identified', \n",
    "    'SV_determined', 'identified', 'Undetermined→identified', \n",
    "    'Repeat_expansion', 'repeat expansion identified', 'mosicism susp',\n",
    "    'SNV_identified;CNV_identified', 'Tandem_repeat_expansion_identified'\n",
    "    ]\n",
    "\n",
    "replace_to_undetermined = [\n",
    "    'On going', 'On_going', 'undetermined', '検体取り下げ', '欠番', 'Unknown',\n",
    "    'Inconclusive', 'サンガーの結果、本家系で見られたCOL4A2バリアントはなかった'\n",
    "    ]\n",
    "\n",
    "df.replace(replace_to_identified, 'Identified', inplace=True)\n",
    "df.replace(replace_to_undetermined, 'Undetermined', inplace=True)\n",
    "df.fillna('Undetermined', inplace=True)\n",
    "df_post.replace(replace_to_identified, 'Identified', inplace=True)\n",
    "df_post.replace(replace_to_undetermined, 'Undetermined', inplace=True)\n",
    "df_post.fillna('Undetermined', inplace=True)\n",
    "\n",
    "if len(df['State'].unique()) > 2:\n",
    "    errmsg = f\"State column has more than 2 unique values. In the {new_excel}.\"\n",
    "    logger.error(errmsg)\n",
    "    exit(1)\n",
    "\n",
    "if len(df_post['State'].unique()) > 2:\n",
    "    errmsg = f\"State column has more than 2 unique values. In the {post_excel}.\"\n",
    "    logger.error(errmsg)\n",
    "    exit(1)\n",
    "\n",
    "# Rename columns\n",
    "rename_dict = {'YCU ID': 'YCU_ID', 'YCUID': 'YCU_ID', \n",
    "               'DNA ID': 'DNA_ID', 'DNAID': 'DNA_ID', \n",
    "               }\n",
    "\n",
    "df.rename(columns=rename_dict, inplace=True)\n",
    "df_old.rename(columns=rename_dict, inplace=True)\n",
    "df_post.rename(columns=rename_dict, inplace=True)\n",
    "\n",
    "# Connect to sqlite3 database\n",
    "ycu_db = 'db/ycudb.db'\n",
    "logger.info(\"Connect to sqlite3 database\")\n",
    "conn = sqlite3.connect(ycu_db)\n",
    "\n",
    "# Create sqlite database (If exists, replace). Three tables will be created.\n",
    "logger.info(\"Create sqlite database\")\n",
    "df.to_sql('new_samples', conn, if_exists='replace', index=False)\n",
    "df_old.to_sql('old_samples', conn, if_exists='replace', index=False)\n",
    "df_post.to_sql('post_samples', conn, if_exists='replace', index=False)\n",
    "\n",
    "# Close connection\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(ycu_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ycu_id = '231694'\n",
    "query = \"SELECT YCU_ID,State FROM new_samples WHERE `YCU_ID` = ?\"\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(query, (ycu_id,))\n",
    "\n",
    "results = cursor.fetchall()\n",
    "for row in results:\n",
    "    print(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import glob\n",
    "\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "# Set up logger\n",
    "from logging import getLogger, StreamHandler, Formatter, INFO\n",
    "\n",
    "logger = getLogger(__name__)\n",
    "format = Formatter(fmt='%(asctime)s [%(levelname)s] - %(message)s',\n",
    "                   datefmt='%Y-%m-%d %H:%M:%S')\n",
    "handler = StreamHandler()\n",
    "handler.setLevel(INFO)\n",
    "handler.setFormatter(format)\n",
    "logger.addHandler(handler)\n",
    "logger.setLevel(INFO)\n",
    "logger.propagate = False\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DFs:\n",
    "    df: pd.DataFrame\n",
    "    df_old: pd.DataFrame\n",
    "    df_post: pd.DataFrame\n",
    "\n",
    "\n",
    "def _find_excel_files() -> tuple:\n",
    "    logger.info(\"Find the excel files\")\n",
    "    old_excel = glob.glob('rawdata/2004*.xlsx')[0]\n",
    "    new_excel = glob.glob('rawdata/自動報告書*')[0]\n",
    "    post_excel = glob.glob('rawdata/郵送*')[0]\n",
    "\n",
    "    return old_excel, new_excel, post_excel\n",
    "\n",
    "\n",
    "def load_excel_file() -> DFs:\n",
    "    old_excel, new_excel, post_excel = _find_excel_files()\n",
    "    ## Columns to use\n",
    "    usecols_new = ['Date', 'YCU ID', 'DNA ID', '病名', 'State', 'Gene', \n",
    "                   'WES batch', '家族関係', 'father DNA ID', 'mother DNA ID', \n",
    "                   'Proband_DNA_ID']\n",
    "\n",
    "    usecols_old = ['Date', 'YCU ID', 'DNA ID', '病名', 'WES batch', \n",
    "                   '家族関係', 'father DNA ID', 'mother DNA ID', \n",
    "                   'Proband_DNA_ID']\n",
    "\n",
    "    usecols_post = ['検体拝受日', 'YCUID', 'DNAID', '診断名', 'State', \n",
    "                    '解析結果(遺伝子名)', 'ProbandID']\n",
    "\n",
    "    # Load excel files as pd.DataFrame\n",
    "    logger.info(f\"Load {new_excel} file\")\n",
    "    df = pd.read_excel(new_excel, dtype=str, sheet_name='database', \n",
    "                    index_col=None, skiprows=3, usecols=usecols_new)\n",
    "    df.dropna(how='all')\n",
    "    df = df[usecols_new]\n",
    "\n",
    "    logger.info(f\"Load {old_excel} file\")\n",
    "    df_old = pd.read_excel(old_excel, index_col=None, usecols=usecols_old)\n",
    "    df_old.dropna(how='all')\n",
    "    df_old = df_old[usecols_old]\n",
    "\n",
    "    logger.info(f\"Load {post_excel} file\")\n",
    "    df_post = pd.read_excel(post_excel, index_col=None, usecols=usecols_post)\n",
    "    df_post.dropna(how='all')\n",
    "    df_post = df_post[usecols_post]\n",
    "\n",
    "    return DFs(df, df_old, df_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = load_excel_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, df_old, df_post = dfs.df, dfs.df_old, dfs.df_post\n",
    "# df_old = dfs.df_old\n",
    "# df_post = dfs.df_post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
